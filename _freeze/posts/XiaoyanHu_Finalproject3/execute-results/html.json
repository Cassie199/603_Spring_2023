{
  "hash": "ef0c29e0b6b356be23d4957b65eb391d",
  "result": {
    "markdown": "---\ntitle: \"Final Project \"\nauthor: \"Xiaoyan\"\ndescription: \"Template of course blog qmd file\"\ndate: \"05/17/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - finalpart1\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n:::\n\n# {.tabset}\n\n## Introduction and background\n\n The Chinese government implemented the one-child policy in 1979, which resulted in the increasing proportion of one-child families and the \"four-two-one\" family structure consisting of four grandparents, two parents, and one child. Despite being blessed with relatively more family and social resources, only children may face physical and socio-psychological problems during development, including an elevated risk for overweight and obesity and negative psychosocial consequences. Previous studies have shown that only children had a higher likelihood of overweight or obesity, compared with children who had one or more siblings. Over obesity, mental healthy is also interesting to explore that how it is related to overweight/obesity, as well as sib-size, in young adolescents affects mental health.。\n \n\n## research questions\n1. Does obesity positively related to mental health?\n2. What are factors that affects mental healthy?\n3. Does sibling or obesity directly related to mental health?\n\n## key predictors\n1. depression rate\n2. sibling number\n3. obesity rate\n4. Family location, finance and education\n\n\n## hypothesis\n1. Higher obesity rate increase the risk of depression\n2. higher family income increase the rate of obesity\n3. More sibling reduce the risk of both depression and anxiety. \n\nIn these hypothesis, the response variables are depression rate, axiety rate and BMI index. The explanatory variables can be factors listed below. Analysis is needed to identify the control variables. For exapmle, in hypothesis 2, family income is the explanatory varible and rate of obsity inidcated as BMI is response varible, the control varible may also be family financial situation. \n\n## data description\n### overlook of data\n\n::: {.cell}\n\n```{.r .cell-code}\ndata<-read_excel(\"/Users/cassie199/Desktop/23spring/603_Spring_2023-1/posts/_data/mentalhealth_data.xlsx\")\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 29\n  T0depres…¹ T0anx…² T1dep…³ T1anx…⁴ Height Weight    WC    HC   SBP   DBP   FBG\n       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1         31      35      41      35   153.   34.6    58  67      98    60   4.4\n2         35      24      35      25   172.   46.1    63  78     110    70   3.9\n3         31      34      37      26   146.   38.9    72  77.7   102    62   4.6\n4         27      31      42      35   162.   46.8    62  80     116    80   4.5\n5         31      26      49      33   154.   36.4    56  72      90    60   4.2\n6         30      28      47      32   164.   40.6    55  73     102    70   3.7\n# … with 18 more variables: TC <dbl>, TG <dbl>, `HDL-C` <dbl>, `LDL-C` <dbl>,\n#   BMI <dbl>, WHR <dbl>, WtHR <dbl>, `Family location` <dbl>,\n#   `Number of siblings` <dbl>,\n#   `How much time do you spend with your father in elementary school?` <dbl>,\n#   `How much time do you spend with your mother in elementary school?` <dbl>,\n#   `Father’s education level` <dbl>, `Mother’s education level` <dbl>,\n#   `Family financial situation` <dbl>, `Sleeping hours` <dbl>, …\n```\n:::\n\n```{.r .cell-code}\nsum(is.na(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 728\n```\n:::\n\n```{.r .cell-code}\nplot(data$T0depression~data$BMI)\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\nThis dataset including 1348 variables and 29 columns. there are 728 NA in this data set. all variables was presented as numberic data. descriptive data was also presented as degrees such as education level, family financial situation and depression rate. By pre-plotting depression rate vs BMI, we can see that some ouliers may need to deal with and there is no siginifcant disrtibution on graph. More data processing is needed in future process.\n\n\nModified column name and \n\n::: {.cell}\n\n```{.r .cell-code}\nvariables <- c(\"Internalizing problem - Depression (SDS)\", \"Internalizing problem - Anxiety (SAS)\", \n               \"Obesity parameters - BMI\", \"Obesity parameters - WC\", \"Obesity parameters - WHR\",\n               \"Obesity parameters - WHtR\", \"Biochemical parameters - TG\", \"Biochemical parameters - FBG\",\n               \"Biochemical parameters - TC\", \"Biochemical parameters - HDL-C\", \"Biochemical parameters - LDL-C\",\n               \"Blood pressure - SBP\", \"Blood pressure - DBP\",\"Family location\", \"Number of siblings\", \" time  spend with father in elementary school?\", \n          \" time spend with mother in elementary school?\", \"Father’s education level\", \n          \"Mother’s education level\", \"Family financial situation\", \"Sleeping hours\", \"Skipping breakfast\", \n          \"Vigorous\", \"Moderate\")\nabreviations <- c(\"Depression\", \"Anxiety\", \"BMI\", \"WC\", \"WHR\", \"WHtR\", \"TG\", \"FBG\", \"TC\", \"HDL-C\", \"LDL-C\", \"SBP\", \"DBP\",\"FL\", \"NS\", \"TFE\", \"TME\", \"FEL\", \"MEL\", \"FS\", \"SL\", \"SB\", \"VG\", \"MD\")\n\n\ncat(\"varible table\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvarible table\n```\n:::\n\n```{.r .cell-code}\nvariable_table <- data.frame(variables, abreviations)\nvariable_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                        variables abreviations\n1        Internalizing problem - Depression (SDS)   Depression\n2           Internalizing problem - Anxiety (SAS)      Anxiety\n3                        Obesity parameters - BMI          BMI\n4                         Obesity parameters - WC           WC\n5                        Obesity parameters - WHR          WHR\n6                       Obesity parameters - WHtR         WHtR\n7                     Biochemical parameters - TG           TG\n8                    Biochemical parameters - FBG          FBG\n9                     Biochemical parameters - TC           TC\n10                 Biochemical parameters - HDL-C        HDL-C\n11                 Biochemical parameters - LDL-C        LDL-C\n12                           Blood pressure - SBP          SBP\n13                           Blood pressure - DBP          DBP\n14                                Family location           FL\n15                             Number of siblings           NS\n16  time  spend with father in elementary school?          TFE\n17   time spend with mother in elementary school?          TME\n18                       Father’s education level          FEL\n19                       Mother’s education level          MEL\n20                     Family financial situation           FS\n21                                 Sleeping hours           SL\n22                             Skipping breakfast           SB\n23                                       Vigorous           VG\n24                                       Moderate           MD\n```\n:::\n\n```{.r .cell-code}\ncolnames(data)<-c(\"T0depression\",\"T0anxiety\",\"T1depression\",\"T1anxiety\",\"Height\",\"Weight\",\"WC\",\"HC\",\"SBP\",\"DBP\",\"FBG\",\"TC\",\"TG\",\"HDL-C\",\"LDL-C\",\"BMI\",\"WHR\",\"WtHR\",\"FL\", \"NS\", \"TFE\", \"TME\", \"FEL\", \"MEL\", \"FS\", \"SL\", \"SB\",\"Vigorous\",\"Moderate\")\n```\n:::\n\n### parameter explaination\nBMI (body mass index) in this study is used as indicator of obisity. NIH divided BMI value into three levels as table below.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the data frame for BMI categories\nbmi_levels <- c(\"Underweight\", \"Normal Weight\", \"Overweight\", \"Obesity\")\nbmi_values <- c(\"<18.5\", \"18.5-24.9\", \"25-29.9\", \">=30\")\nbmi_table <- data.frame(Category = bmi_levels, BMI = bmi_values)\n\n\n# Print the BMI category table\ncat(\"\\nBMI Categories\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nBMI Categories\n```\n:::\n\n```{.r .cell-code}\nprint(bmi_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Category       BMI\n1   Underweight     <18.5\n2 Normal Weight 18.5-24.9\n3    Overweight   25-29.9\n4       Obesity      >=30\n```\n:::\n:::\n\n## hypothesis test\n\n### 1. Higher obesity rate increase the risk of depression\nH0=no relationship between obesity rate and the risk of depression\nHa=higher obesity rate increases the risk of depression\n\nIn order to prove this hypothesis, linear model was used to calculate relationship between depression rate and BMI.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#linear regression of depresison and BMI\nlm0<-lm(T1depression ~ BMI, data = data)\nsummary(lm0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T1depression ~ BMI, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.2371  -6.2000   0.1719   6.2964  21.9845 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 40.75036    1.50580  27.062   <2e-16 ***\nBMI         -0.09528    0.07803  -1.221    0.222    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.093 on 1308 degrees of freedom\n  (38 observations deleted due to missingness)\nMultiple R-squared:  0.001139,\tAdjusted R-squared:  0.0003749 \nF-statistic: 1.491 on 1 and 1308 DF,  p-value: 0.2223\n```\n:::\n:::\n\nThe BMI coefficient (-0.09528) represents the estimated change in the depression score for a one-unit increase in BMI. For each unit increase in BMI, the depression score decreases by 0.09528. With p-value of 0.222, the coefficient is not significant. Therefore, there is no strong evidence of a linear relationship between BMI and depression. the residuals range from -19.2371 to 21.9845. The residual standard error is relatively high also indicates the model is not fit to the data. F-staistic gives an overall sinificance of the model and with a high p-value, this model is also not statically significant as a whole. The multiple R-squared value (0.001139) represents the proportion of variance in the depression score explained by the model and only 0.1139% of the variability in depression can be attributed to the linear relationship with BMI.\nThe adjusted R-squared value (0.0003749) adjusts the multiple R-squared value for the number of predictors in the model. It penalizes the inclusion of unnecessary predictors. A lower adjusted  R-squared suggests that the model does not provide a good fit to the data. \n\nIn summary, based on the provided output, there is no strong evidence to support a linear relationship between BMI and depression. The coefficient for BMI is not statistically significant, and the model's overall fit is weak (low R-squared values and non-significant F-statistic). \n\n::: {.cell}\n\n```{.r .cell-code}\n#diagnostic\nplot(lm0)\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-6-4.png){width=672}\n:::\n:::\n\nLinear regression diagnostic plot was used to assess the assumptions and evaluate the performance. The straight line\n\nIn a \"residuals vs. fitted\" plot, a horizontal red line is typically used to represent the mean or expected value of the residuals. This line helps to assess the assumption of linearity and provides a reference for evaluating the distribution of residuals around this line.\n\nIdeally, the residuals should be evenly distributed above and below the horizontal red line, indicating that they have a mean of zero and are randomly scattered around this line. This suggests that the linear regression model is unbiased and captures the relationship between the predictor variables and the response variable adequately.\n\nIf the residuals show a clear pattern or systematic deviation from the horizontal red line, it indicates a violation of the linearity assumption. This could suggest that the relationship between the predictor variable(s) and the response variable is not adequately captured by the linear model. In such cases, you might need to consider alternative modeling approaches or explore potential transformations of the variables to improve the linearity assumption.\n\nIn summary, the horizontal red line in a \"residuals vs. fitted\" plot represents the mean or expected value of the residuals. Its main purpose is to assess the linearity assumption of the linear regression model and evaluate the distribution of residuals around this line.\n\n\nnormal qq plot\n\nA straight pattern on a normal quantile-quantile (QQ) plot suggests that the residuals of a linear regression model follow a normal distribution. The QQ plot is a graphical tool used to assess whether the residuals conform to the assumption of normality.\n\nIn a normal QQ plot, the observed quantiles of the residuals are plotted against the expected quantiles of a normal distribution. If the residuals are normally distributed, the points on the QQ plot should roughly follow a straight line. Deviations from the straight line indicate departures from normality.\n\nA straight pattern on the QQ plot suggests that the residuals are normally distributed, which is desirable for linear regression analysis. It indicates that the assumptions of normality are met, allowing for reliable statistical inference and accurate interpretation of the model results.\n\nHowever, if the QQ plot exhibits curvature, skewness, or any other non-linear patterns, it suggests that the residuals deviate from normality. This can have implications for the validity of statistical tests, confidence intervals, and model predictions. In such cases, it may be necessary to consider alternative modeling approaches or transformations of variables to address the departure from normality.\n\nIn summary, a straight pattern on a normal QQ plot indicates that the residuals of a linear regression model follow a normal distribution, supporting the assumption of normality.\n\n\nIn a scale-location plot (also known as spread-location or spread-versus-level plot), a straight red line typically indicates homoscedasticity, which means that the residuals have a constant variance across different levels of the predictor variable(s).\n\nThe scale-location plot is a diagnostic plot used to assess the assumption of homoscedasticity in a linear regression model. It plots the absolute values of the standardized residuals (or their square root) against the predicted values or other measures of the predictor variable(s). The plot helps to detect any systematic patterns in the spread (variance) of the residuals.\n\nIf the points in the scale-location plot are randomly scattered around a horizontal red line, it suggests that the residuals have a constant variance across the range of the predictor variable(s). This is desirable and indicates that the assumption of homoscedasticity is met.\n\nHowever, if the points show a distinct pattern, such as a funnel shape, a widening or narrowing of the spread, or any other non-random trend, it suggests heteroscedasticity. Heteroscedasticity means that the variance of the residuals is not constant across the predictor variable(s) and violates the assumption of homoscedasticity. In such cases, the reliability of the regression model's predictions and the validity of statistical inference may be compromised.\n\nAddressing heteroscedasticity may involve transforming variables, using weighted regression techniques, or considering alternative modeling approaches to account for the varying variance of the residuals.\n\nIn summary, a straight red line in a scale-location plot suggests that the residuals have a constant variance (homoscedasticity), supporting the assumption of homoscedasticity in a linear regression model.\n\n\nBy examining these diagnostic plots, you can assess the assumptions of linearity, normality, constant variance, and identify potential outliers or influential observations. Deviations from the expected patterns in these plots may indicate issues with the model's assumptions, and further investigation or model refinement may be necessary.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#visualization\nggplot(data, aes(x = BMI, y = T1depression)) +\n  geom_point(color = \"indianred\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkred\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 38 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 38 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplott1depression<-data$T1depression[1:length(predict(lm0))]\nplot_data <- data.frame(Predicted_value = predict(lm0),  \n                       Observed_value = plott1depression)\nggplot(plot_data, aes(x = Predicted_value, y = Observed_value)) +\n                  geom_point() +\n                 geom_abline(intercept = 0, slope = 1, color = \"green\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\nOther varibles were introduced alone with BMI. The result shows that time spend with father in elementary school and skipping breakfast have significant influence in children's depression rate. Specifically, the less time spend with father in elementary school, the more possible to obtain a increase depressin rate. Also skipping more breakfast also have a heavy increase in depression rate. \nThe diagostic result shows \n\n::: {.cell}\n\n```{.r .cell-code}\n#linear regression model 2\nlm1<-lm(T1depression ~ BMI+NS+TFE+TME+FEL+MEL+FL+SL+SB, data = data)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T1depression ~ BMI + NS + TFE + TME + FEL + MEL + \n    FL + SL + SB, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.3852  -5.9985   0.1987   6.4197  21.1941 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.55778    2.88686  14.742  < 2e-16 ***\nBMI         -0.10358    0.07798  -1.328   0.1843    \nNS           0.72821    0.51703   1.408   0.1592    \nTFE         -0.57069    0.24271  -2.351   0.0189 *  \nTME         -0.18783    0.30401  -0.618   0.5368    \nFEL         -0.28747    0.24332  -1.181   0.2376    \nMEL         -0.22372    0.26894  -0.832   0.4056    \nFL           0.09777    0.18801   0.520   0.6031    \nSL           0.10706    0.38873   0.275   0.7831    \nSB           1.47402    0.31288   4.711 2.73e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.967 on 1300 degrees of freedom\n  (38 observations deleted due to missingness)\nMultiple R-squared:  0.0379,\tAdjusted R-squared:  0.03124 \nF-statistic: 5.691 on 9 and 1300 DF,  p-value: 9.18e-08\n```\n:::\n\n```{.r .cell-code}\n#diagnostic\nplot(lm1)\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-8-4.png){width=672}\n:::\n:::\n\nTo verify if the model is correct, some of varibles with large p value are deleted for backward eklimination. \"Time spend with mother in elementary school\", \"Father's educaion level\", \"sleeping time\" are deleted comparing to the model before. In this case, \"Time spend with father in elementary school\" and \"skipping breakfast\" still above the significant level. By comparing the adjusted R square of two models(0.03124 and 0.03321). There was no not two big difference in these two models. \n\n::: {.cell}\n\n```{.r .cell-code}\n#linear regression model 3\nlm2<-lm(T1depression ~ BMI+NS+TFE+FEL+SB, data = data)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T1depression ~ BMI + NS + TFE + FEL + SB, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.9398  -6.0354   0.2289   6.3596  20.8288 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 41.91051    2.17737  19.248  < 2e-16 ***\nBMI         -0.10798    0.07716  -1.399  0.16193    \nNS           0.73126    0.45738   1.599  0.11011    \nTFE         -0.64654    0.20647  -3.131  0.00178 ** \nFEL         -0.33519    0.23154  -1.448  0.14795    \nSB           1.51314    0.31049   4.873 1.23e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.959 on 1304 degrees of freedom\n  (38 observations deleted due to missingness)\nMultiple R-squared:  0.03681,\tAdjusted R-squared:  0.03312 \nF-statistic: 9.967 on 5 and 1304 DF,  p-value: 2.26e-09\n```\n:::\n\n```{.r .cell-code}\n#diagnostic \npar(mfrow = c(2,3))\nplot(lm2)\n#compare predicted value with observe value\nlm3<-lm(T1depression ~ TFE, data = data)\n\nplot_data <- data.frame(Predicted_value = predict(lm3),  \n                       Observed_value = data$T1depression[1:length(predict(lm3))])\nggplot(plot_data, aes(x = Predicted_value, y = Observed_value)) +\n                  geom_point() +\n                 geom_abline(intercept = 0, slope = 1, color = \"green\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n```{.r .cell-code}\nggplot(data, aes(x = T1depression, y = SB)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nIn summary, based on the provided output, there is no strong evidence to support a linear relationship between BMI and depression. The coefficient for BMI is not statistically significant, and the model's overall fit is weak (low R-squared values and non-significant F-statistic). Therefore, we fail to reject the null hypothesis.  \n\n\n### 2. higher family income increase the rate of obesity\nH0=no relationship between family income and rate of obesity \nHa=higher family income increase the rate of obesity\n\nBased on this data, we may also explore what factors may affect the obsity rate. Here we made a hypothsis as higher family income increase the rate of obesity. Due to most of the varibles are ordinal varibles, oridinal logistic regression is applied in this slot to verify the hypothesis. \n\n::: {.cell}\n\n```{.r .cell-code}\n#convert BMI to ordinal varible\ndata$BMI_category <- cut(data$BMI, \n                       breaks = c(-Inf, 18.5, 24.9, Inf),\n                       labels = c(\"Underweight\", \"Normal weight\", \"Overweight\"))\ndata$BMI_rank <- as.factor(unclass(data$BMI_category))\n\n# Visualizing data\n# Filter out rows with NA values in BMI_rank or FS\nfiltered_data <- data[complete.cases(data$BMI_rank, data$FS), ]\n\n# Create the plot with filtered data\nggplot(filtered_data, aes(x = BMI_category, y = FS)) +\n  geom_boxplot(size = 0.75, color = \"indianred\") +\n  geom_jitter(alpha = 0.5, color = \"red\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))+\n  ylab(\"Financial Situation\")\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# #Fit BMI rank and family finanacial situation into ordinal logit model\nmodel <- polr(BMI_rank ~ FS, data = data, Hess=TRUE)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = BMI_rank ~ FS, data = data, Hess = TRUE)\n\nCoefficients:\n     Value Std. Error t value\nFS -0.1883    0.07865  -2.394\n\nIntercepts:\n    Value   Std. Error t value\n1|2 -0.7067  0.2554    -2.7672\n2|3  2.6195  0.2828     9.2639\n\nResidual Deviance: 2173.226 \nAIC: 2179.226 \n(36 observations deleted due to missingness)\n```\n:::\n\n```{.r .cell-code}\n#p value\nctable <- coef(summary(model))\np <- pnorm(abs(ctable[, \"t value\"]), lower.tail = FALSE) * 2\nctable <- cbind(ctable, \"p value\" = p)\nctable\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Value Std. Error   t value      p value\nFS  -0.1883107  0.0786533 -2.394187 1.665724e-02\n1|2 -0.7067002  0.2553870 -2.767174 5.654453e-03\n2|3  2.6194751  0.2827624  9.263873 1.971474e-20\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Getting odds-ratio\nexp(coef(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       FS \n0.8283573 \n```\n:::\n:::\n\n The coefficient for the variable financial situation is -0.1883. This indicates that a one-unit increase in FS is associated with a decrease in the log-odds of moving to a higher BMI rank by 0.1883. The negative sign suggests that higher values of FS are associated with a lower likelihood of being in a higher BMI rank.\nIntercepts:\n1|2: The intercept for the transition from rank 1 to rank 2 is -0.7067. This intercept represents the baseline log-odds of being in rank 2 when FS is zero (or at its reference level).\n2|3: The intercept for the transition from rank 2 to rank 3 is 2.6195. This intercept represents the baseline log-odds of being in rank 3 when FS is zero (or at its reference level).\nResidual Deviance: The residual deviance is a measure of how well the model fits the data. In this case, the residual deviance is 2173.226.\nAIC: The Akaike Information Criterion (AIC) is a measure of the model's quality and complexity. A lower AIC value indicates a better-fitting model. In this case, the AIC is 2179.226.\nNote: The message \"(36 observations deleted due to missingness)\" indicates that 36 observations were removed from the analysis due to missing values.\n\nIt's important to consider the statistical significance of the coefficients (t values) and the overall model fit when interpreting the results. Additionally, the interpretation of the coefficients may depend on the specific context and the scale and nature of the variables involved in the model.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#introduce more variables to compare\n\nLR1<-polr(BMI_rank~SL+SB+FS, data = data, Hess = TRUE, method = \"logistic\")\nSUM1<-summary(LR1)\nSUM1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = BMI_rank ~ SL + SB + FS, data = data, Hess = TRUE, \n    method = \"logistic\")\n\nCoefficients:\n     Value Std. Error t value\nSL -0.5179    0.09863  -5.250\nSB  0.2064    0.07715   2.676\nFS -0.1336    0.08003  -1.669\n\nIntercepts:\n    Value   Std. Error t value\n1|2 -1.3558  0.3381    -4.0102\n2|3  2.0251  0.3551     5.7024\n\nResidual Deviance: 2136.853 \nAIC: 2146.853 \n(36 observations deleted due to missingness)\n```\n:::\n\n```{.r .cell-code}\n#p value\nctable2 <- coef(summary(LR1))\np <- pnorm(abs(ctable2[, \"t value\"]), lower.tail = FALSE) * 2\nctable2 <- cbind(ctable2, \"p value\" = p)\nctable2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Value Std. Error   t value      p value\nSL  -0.5178720 0.09863452 -5.250414 1.517580e-07\nSB   0.2064347 0.07715030  2.675748 7.456279e-03\nFS  -0.1336130 0.08003340 -1.669465 9.502524e-02\n1|2 -1.3557600 0.33807702 -4.010210 6.066466e-05\n2|3  2.0251068 0.35513075  5.702426 1.181141e-08\n```\n:::\n:::\n\nInterpreting the coefficients:\n\nFor every one-unit increase in SL, the log-odds of moving up one category in BMI_rank decrease by 0.5179.\nFor every one-unit increase in SB, the log-odds of moving up one category in BMI_rank increase by 0.2064.\nFor every one-unit increase in FS, the log-odds of moving up one category in BMI_rank decrease by 0.1336.\nThe intercepts represent the thresholds between the different categories of the dependent variable. The intercept for 1|2 represents the threshold between categories 1 and 2, and the intercept for 2|3 represents the threshold between categories 2 and 3.\nAccording to P values, all coeffients were significant. Comparing the AIC value to previous model, the later model is slightly better. \n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(SUM1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Value Std. Error   t value\nSL  -0.5178720 0.09863452 -5.250414\nSB   0.2064347 0.07715030  2.675748\nFS  -0.1336130 0.08003340 -1.669465\n1|2 -1.3557600 0.33807702 -4.010210\n2|3  2.0251068 0.35513075  5.702426\n```\n:::\n\n```{.r .cell-code}\nexp(coef(SUM1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        Value Std. Error      t value\nSL  0.5957870   1.103663 5.245348e-03\nSB  1.2292875   1.080204 1.452320e+01\nFS  0.8749286   1.083323 1.883478e-01\n1|2 0.2577513   1.402249 1.812958e-02\n2|3 7.5769204   1.426367 2.995934e+02\n```\n:::\n\n```{.r .cell-code}\n### Predict probability\n# Create a data frame with possible IV values\nnewdat <- data.frame(\n  FS = rep(1:5, each = 272),\n  SL = rep(1:4, each = 340),\n  SB = rep(1:4, each = 340),\n  BMI = rep(seq(from = 12.8, to = 39, length.out = 340), 4))\n  \n\n# Get the predicted probability \nnewdat <- cbind(newdat, predict(LR1, newdat, type = \"probs\"))\n\n#show first few rows\nhead(newdat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  FS SL SB      BMI         1         2          3\n1  1  1  1 12.80000 0.2868546 0.6351684 0.07797694\n2  1  1  1 12.87729 0.2868546 0.6351684 0.07797694\n3  1  1  1 12.95457 0.2868546 0.6351684 0.07797694\n4  1  1  1 13.03186 0.2868546 0.6351684 0.07797694\n5  1  1  1 13.10914 0.2868546 0.6351684 0.07797694\n6  1  1  1 13.18643 0.2868546 0.6351684 0.07797694\n```\n:::\n\n```{.r .cell-code}\n# Keeping the category with the highest probability\nlnewdat <- melt(newdat, id.vars = c(\"FS\", \"SL\", \"SB\",\"BMI\"),\n                variable.name = \"Level\", value.name=\"Probability\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in melt(newdat, id.vars = c(\"FS\", \"SL\", \"SB\", \"BMI\"), variable.name = \"Level\", : could not find function \"melt\"\n```\n:::\n\n```{.r .cell-code}\n# view first few rows\nhead(lnewdat)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(lnewdat): object 'lnewdat' not found\n```\n:::\n\n```{.r .cell-code}\n# Visualizing probability\nggplot(lnewdat, aes(x = BMI, y = Probability, colour = Level)) +\n  geom_line() + facet_grid(FS ~ SL, labeller=\"label_both\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(lnewdat, aes(x = BMI, y = Probability, colour = Level)): object 'lnewdat' not found\n```\n:::\n\n```{.r .cell-code}\n#plot\nggplot(data, aes(x = SL, y = BMI)) +\n  geom_point(color = \"red4\") +\n  geom_smooth(method = \"lm\", se = FALSE,color=\"indianred\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 36 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 36 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(lm(BMI~FS+SL+SB, data = data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = BMI ~ FS + SL + SB, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8387 -1.8551 -0.4147  1.2847 19.9025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 20.22819    0.47823  42.298  < 2e-16 ***\nFS          -0.01293    0.11402  -0.113   0.9097    \nSL          -0.66630    0.13769  -4.839 1.46e-06 ***\nSB           0.23808    0.10978   2.169   0.0303 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.839 on 1308 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.02203,\tAdjusted R-squared:  0.01979 \nF-statistic: 9.823 on 3 and 1308 DF,  p-value: 2.08e-06\n```\n:::\n:::\n\n \n\n### 3. More sibling reduce the risk of both depression and anxiety. \n\n::: {.cell}\n\n```{.r .cell-code}\nunique(data$NS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 1\n```\n:::\n\n```{.r .cell-code}\nggplot(data, aes(x = NS, y = T1depression)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data, aes(x = NS, y = T1depression)) +\n  geom_boxplot()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Continuous x aesthetic\nℹ did you forget `aes(group = ...)`?\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndata$NS <- factor(data$NS)\nt.test(T1depression ~ NS, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  T1depression by NS\nt = -2.6337, df = 1252.5, p-value = 0.008551\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -2.0381547 -0.2979518\nsample estimates:\nmean in group 1 mean in group 2 \n       38.38127        39.54932 \n```\n:::\n:::\n\n\n\nIn this case, the sample estimate of the correlation coefficient (rho) is 0.1184734, indicating a positive correlation between T0depression and NS. However, the p-value of the test is 0.008575, which is less than 0.05, suggesting that the correlation is statistically significant at a 5% level of significance.\n\nTherefore, we can conclude that there is a significant positive correlation between the number of siblings (NS) and the degree of depression  in this dataset.\n\nBy carrying out a Welch t-test, the group with more siblings have higher depression index and p value <0.05 indicates the result is siginifcant. (Not sure why the confident interval is negtive and none of the data was negative. )\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = NS, y = T1anxiety)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndata$NS <- as.numeric(data$NS)\ncor.test(data$T1anxiety,data$NS, method = c(\"spearman\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in cor.test.default(data$T1anxiety, data$NS, method = c(\"spearman\")):\nCannot compute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tSpearman's rank correlation rho\n\ndata:  data$T1anxiety and data$NS\nS = 343033890, p-value = 8.796e-09\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1559788 \n```\n:::\n\n```{.r .cell-code}\nfit3<-lm(T1anxiety ~ NS, data = data)\nsummary(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = T1anxiety ~ NS, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.906  -3.997   0.003   3.003  33.003 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  30.0883     0.5185  58.030  < 2e-16 ***\nNS            1.9091     0.3411   5.597 2.64e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.207 on 1344 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.02278,\tAdjusted R-squared:  0.02205 \nF-statistic: 31.32 on 1 and 1344 DF,  p-value: 2.643e-08\n```\n:::\n:::\n\n### others\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the data frame for SAS and SDS scales\nsas_levels <- c(\"Normal\", \"Mild to Moderate\", \"Marked to Severe\", \"Extreme\")\nsas_scores <- c(\"<45\", \"45-59\", \"60-74\", \">=75\")\nsas_table <- data.frame(Level = sas_levels, Score = sas_scores)\n\nsds_levels <- c(\"Normal\", \"Mild\", \"Moderate to Marked Major\", \"Severe or Extreme Major\")\nsds_scores <- c(\"<50\", \"50-59\", \"60-69\", \">=70\")\nsds_table <- data.frame(Level = sds_levels, Score = sds_scores)\n# Print the SAS scale table\ncat(\"Self-rating Anxiety Scale (SAS)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSelf-rating Anxiety Scale (SAS)\n```\n:::\n\n```{.r .cell-code}\nprint(sas_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Level Score\n1           Normal   <45\n2 Mild to Moderate 45-59\n3 Marked to Severe 60-74\n4          Extreme  >=75\n```\n:::\n\n```{.r .cell-code}\n# Print the SDS scale table\ncat(\"\\nSDS scores (SDS)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSDS scores (SDS)\n```\n:::\n\n```{.r .cell-code}\nprint(sds_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Level Score\n1                   Normal   <50\n2                     Mild 50-59\n3 Moderate to Marked Major 60-69\n4  Severe or Extreme Major  >=70\n```\n:::\n\n```{.r .cell-code}\n# Create sample data\n\nplot(data$BMI~data$T1depression)\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(data$T1depression~data$FL)\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndata$BMI_category <- cut(data$BMI, \n                       breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),\n                       labels = c(\"Underweight\", \"Normal weight\", \"Overweight\", \"Obesity\"))\ndata$Depression_category <- cut(data$T1depression, \n                       breaks = c(0,45,\t59,74,75),\n                       labels = c(\"Normal\", \"Mild\", \"Moderate to Marked Major\", \"Severe or Extreme Major\"))\n# Plot the bar chart\n```\n:::\n\n \n\n\n## Answers to the feedbacks on check in 1\n\nHere are a few things you may want to work on in future steps:\n1. Please provide more information of the dataset: what each variable means (e.g. WC, HC, SBP etc) and how it is measured. This is to make sure audiences understand your confounders.\n  a table with explaination of abrivation is updated in data description\n\n2. Since gender is one of your key predictors, you may consider using the interaction between gender and other key variables in the model to see whether gender influences the impact of other predictors. Also, seem I didn't find the gender variable in the dataset you provided?\n  Thanks for pointing out. Since gender is missiong, I will not use gender as a key predicor. \n  \n3. As you mentioned, there are some outliers in the data, especially the one on the top-right corner. This outlier can change the slope of the regression. Also, the relationship between BMI and depression is not very clear in the graph, as you mentioned, more data processing is needed. You can also try plotting different groups (e.g. gender, family location) in different colors to see if there's any pattern.\n\nThanks for the comments, I will try to process the data this time  and plot more patterns. \n\n## Questions need to be addressed\n1. the varibles such as family locations or education level can be expressed either as rank or ordinal, as drawed below,it is hard to find a correlationship with this kind of varibles. How can i explore the relationship between an ordinal varible and a continuous varible?\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(data[c(\"T1depression\",\"T1anxiety\",\"BMI\",\"FL\", \"NS\", \"TFE\", \"TME\", \"FEL\")])\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\npairs(data[c(\"T1depression\",\"T1anxiety\", \"MEL\", \"FS\", \"SL\", \"SB\",\"Vigorous\",\"Moderate\")])\n```\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n:::\n\n2. as some of the continuous varibles can also converted to ordinal varibles, what would be some method or test good to find the relationship between them?\n\n::: {.cell}\n\n```{.r .cell-code}\n#convert continuous varibles into categorical varibles\ndata$FL1 <- factor(sample(1:5, 1348, replace = TRUE), levels = 1:5, \n                            labels = c(\"Rural\", \"Suburban\", \"Urban\", \"City\", \"Metropolis\"))\ndata$BMI_category <- cut(data$BMI, \n                       breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),\n                       labels = c(\"Underweight\", \"Normal weight\", \"Overweight\", \"Obesity\"))\ndata$Depression_category <- cut(data$T1depression, \n                       breaks = c(0,45,\t59,74,75),\n                       labels = c(\"Normal\", \"Mild\", \"Moderate to Marked Major\", \"Severe or Extreme Major\"))\n#plot\nggplot(data, aes(x = FL1, y = BMI, fill = BMI_category)) + \n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_fill_manual(values = c(\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\")) +\n  xlab(\"Family location\") + ylab(\"BMI\") + \n  ggtitle(\"BMI category and family location\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 36 rows containing missing values (`position_stack()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data, aes(x = FL1, y = T1depression, fill = Depression_category)) + \n  geom_bar(stat = \"identity\", position = \"stack\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`position_stack()`).\n```\n:::\n\n::: {.cell-output-display}\n![](XiaoyanHu_Finalproject3_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::",
    "supporting": [
      "XiaoyanHu_Finalproject3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}